import json
import re
from abc import ABC, abstractstaticmethod
from dataclasses import dataclass, field
from enum import Enum
from math import sqrt
from typing import Any, Dict, List, Type, Union

import tiktoken

from app.client._neo4j import (BlockFilter, DocumentFilter, Limit, NameFilter,
                                Neo4j, OrderBy, OrderDirection, QueryFilter)
from app.client._openai import OpenAI
from app.client._pinecone import Pinecone
from app.mrkl.open_ai import OpenAIChat
from app.mrkl.prompt import (ChatPrompt, ChatPromptMessage,
                             ChatPromptMessageRole)

# ----------------------------------------------------------------------------
# Constants
# ----------------------------------------------------------------------------

SYSTEM_PROMPT = '''You are a data agent for a large company.
You have access to a specialized database that contains all of the company's data.
The database is a graph database, which means that all of the data is stored as nodes and edges.
A node can be a name, a page, or a block. A name is a reference to an entity, like a person or company.
A page is a document, like an email or a report. A block is a piece of text within a page.
Below are descriptions about the different block types:

{block_descriptions}

Given a question, your job is to create a well-formed query to retrieve information from the database that will help answer the question.
The query must be formatted in a specific way, and the values must make sense based on the question.
All fields in the query are optional, so you can leave any field blank if you don't know what to put there.
Below is a schema for the query and explanations for what each field means:

{json_schema}

{component_descriptions}

Use the examples below to understand what a well-formed query looks like.
--------
EXAMPLE 1
Question: What are the subjects of my last 10 emails from Troy Wilkerson?
Query: {{
 "names": ["Troy Wilkerson"],
 "time_sort": {{
  "ascending": false,
  "count": 10
 }},
 "integrations": ["email"],
 "blocks": ["title"],
 "search_method": "exact",
 "return_type": "blocks"
}}

EXAMPLE 2
Question: What are John Doe\'s strengths as an employee?
Query: {{
 "search_method": "relevant",
 "return_type": "blocks"
}}'''

# ----------------------------------------------------------------------------
# Query
# ----------------------------------------------------------------------------
class QueryComponent(ABC):
    '''An abstract class for a component of a Query.'''
    @abstractstaticmethod
    def from_llm_response(s: str) -> 'QueryComponent':
        '''Converts a string generated by an LLM to a QueryComponent object.

        Args:
            s (str): The string from the LLM.

        Returns:
            QueryComponent: The QueryComponent object.
        '''
        raise NotImplementedError

    @abstractstaticmethod
    def description_for_prompt() -> str:
        '''Returns a description of the component for use in a prompt.

        Returns:
            str: The description.
        '''
        raise NotImplementedError
    
    @abstractstaticmethod
    def json_for_prompt() -> str:
        '''Returns how the component should be represented in the prompt's
        sample JSON.
        
        Returns:
            str: The JSON.
        '''
        raise NotImplementedError
    
    @staticmethod
    def get_component_descriptions() -> str:
        '''Returns a description of all QueryComponents for use in a prompt.

        Returns:
            str: The description.
        '''
        return '\n'.join([c.description_for_prompt() for c in
                          QueryComponent.list_components()])
    
    @staticmethod
    def get_json_schema() -> str:
        '''Returns a JSON schema for all QueryComponents for use in a prompt.

        Returns:
            str: The JSON schema.
        '''
        return '{\n' + ',\n'.join([c.json_for_prompt() for c in
                                   QueryComponent.list_components()]) + '\n}'

    @staticmethod
    def get_component_from_json_key(key: str) -> 'QueryComponent':
        lookup = {
            'names': NamesFilter,
            'time_frame': AbsoluteTimeFilter,
            'time_sort': RelativeTimeFilter,
            'sources': IntegrationsFilter,
            'blocks': BlocksFilter,
            'search_method': SearchMethod,
            'return_type': ReturnType,
        }
        if key not in lookup:
            raise ValueError(f'Invalid key: {key}')
        return lookup[key]
    
    @staticmethod
    def list_components() -> List['QueryComponent']:
        '''Returns a list of all QueryComponents.

        Returns:
            List[QueryComponent]: The list of QueryComponents.
        '''
        return [
            NamesFilter,
            AbsoluteTimeFilter,
            RelativeTimeFilter,
            IntegrationsFilter,
            BlocksFilter,
            SearchMethod,
            ReturnType,
        ]

@dataclass
class NamesFilter(QueryComponent):
    '''Enforces that only results linked to these names are considered. e.g.
    "Troy Wilkerson", "Mimo"'''
    names: List[str]

    @staticmethod
    def from_llm_response(llm_response: List[str]) -> 'NamesFilter':
        if not NamesFilter._validate_llm_response(llm_response):
            print('Failed to create NamesFilter from LLM response:',
                  llm_response)
            return None
        return NamesFilter(llm_response)
        
    @staticmethod
    def description_for_prompt() -> str:
        return ('names: Identify names of people, companies, or other '
                'entites that are related to the creation of the pages you '
                'are looking for. Do not include all names that appear in '
                'the question. For example, if you are looking for an email '
                'to Beth Harmon, include "Beth Harmon". However, if you are '
                'looking for an email about Google, do not include "Google".')
    
    @staticmethod
    def json_for_prompt() -> str:
        return (' "names": string[]')

    @staticmethod
    def _validate_llm_response(llm_response: List[str]) -> bool:
        return bool(llm_response)

@dataclass
class AbsoluteTimeFilter(QueryComponent):
    '''Enforces that only results within this time frame are considered. e.g.
    "between 2020 and 2022", "in the last 5 days"'''
    start: int
    end: int

    @staticmethod
    def from_llm_response(
        llm_response: Dict[str, str]) -> 'AbsoluteTimeFilter':
        # llm_response should be a dictionary with two keys: 'start' and
        # 'end'. Each value should be a string in the format 'YYYY-MM-DD'.
        if not AbsoluteTimeFilter._validate_llm_response(llm_response):
            print('Failed to create AbsoluteTimeFilter from LLM response:',
                  llm_response)
            return None
        start = _format_date(llm_response['start'])
        end = _format_date(llm_response['end'])
        return AbsoluteTimeFilter(start, end)

    @staticmethod
    def description_for_prompt() -> str:
        return ('time_frame: Include a time frame if the creation date of '
                'the information that can answer the question is limited '
                'to a specific time period. The time frame should be '
                'specified as a start and end date.')
    
    @staticmethod
    def json_for_prompt() -> str:
        return (' "time_frame": {\n'
                '  "start": string,\n'
                '  "end": string\n'
                ' }')

    @staticmethod
    def _validate_llm_response(llm_response: List[str]) -> bool:
        if not (llm_response and 'start' in llm_response and
                'end' in llm_response):
            return False
        start = llm_response['start']
        end = llm_response['end']
        for time in [start, end]:
            if not re.match(r'\d{4}-\d{2}-\d{2}', str(time)):
                return False
        return True

@dataclass
class RelativeTimeFilter(QueryComponent):
    '''Enforces relative ordering of results based on time. e.g. 
    "most recent", "the five oldest"'''
    ascending: bool
    count: int

    @staticmethod
    def from_llm_response(
        llm_response: Dict[str, Union[bool, int]]) -> 'RelativeTimeFilter':
        # llm_response should be a dictionary with two keys: 'ascending' and
        # 'count'. The value of 'ascending' should be a boolean and the value
        # of 'count' should be an integer.
        if not RelativeTimeFilter._validate_llm_response(llm_response):
            print('Failed to create RelativeTimeFilter from LLM response:',
                  llm_response)
            return None
        ascending = llm_response['ascending']
        count = llm_response['count']
        return RelativeTimeFilter(ascending, count)
    
    @staticmethod
    def description_for_prompt() -> str:
        return ('time_sort: Think about whether the question references a '
                'relative ordering of results based on time. If it does, '
                'identify whether the results should be sorted in ascending '
                'or descending order and how many results are requested.')

    @staticmethod
    def json_for_prompt() -> str:
        return (' "time_sort": {\n'
                '  "ascending": boolean,\n'
                '  "count": integer\n'
                ' }')
    
    @staticmethod
    def _validate_llm_response(
        llm_response: Dict[str, Union[bool, int]]) -> bool:
        if not (llm_response and 'ascending' in llm_response and
                'count' in llm_response):
            return False
        ascending = llm_response['ascending']
        count = llm_response['count']
        if not (isinstance(ascending, bool) and isinstance(count, int)
                and count > 0):
            return False
        return True

class Integration(Enum):
    CRM = 'crm'
    CUSTOMER_SUPPORT = 'customer_support'
    DOCUMENTS = 'documents'
    EMAIL = 'email'

@dataclass
class IntegrationsFilter(QueryComponent):
    '''Enforces that only results from these integrations are considered. e.g.
    'gmail', 'zendesk' '''
    integrations: List[Integration]

    @staticmethod
    def from_llm_response(llm_response: List[str]) -> 'IntegrationsFilter':
        if not llm_response:
            return None
        try:
            integrations = [Integration(integration) for integration in
                            llm_response]
        except ValueError:
            print('Failed to create IntegrationsFilter from LLM response:',
                  llm_response)
            return None
        return IntegrationsFilter(integrations)
    
    @staticmethod
    def description_for_prompt() -> str:
        data_sources = ', '.join([f'"{integration.value}"' for integration in
                                  Integration])
        data_sources = f'[{data_sources}]'
        return ('sources: Identify any data sources that are referenced in '
                'the question. The possible data sources are: '
                f'{data_sources}.')

    @staticmethod
    def json_for_prompt() -> str:
        return ' "sources": string[]'

class Block(Enum):
    BODY = 'body'
    COMMENT = 'comment'
    CONTACT = 'contact'
    DEAL = 'deal'
    MEMBERS = 'members'
    SUMMARY = 'summary'
    TITLE = 'title'

@dataclass
class BlocksFilter(QueryComponent):
    '''Enforces that only results from these blocks are considered. e.g.
    "title contains", "summarize"'''
    blocks: List[Block]

    @staticmethod
    def from_llm_response(llm_response: List[str]) -> 'BlocksFilter':
        if not llm_response:
            return None
        try:
            blocks = [Block(block) for block in llm_response]
        except ValueError:
            print('Failed to create BlocksFilter from LLM response:',
                  llm_response)
            return None
        return BlocksFilter(blocks)
    
    @staticmethod
    def description_for_prompt() -> str:
        blocks = ', '.join([f'"{block.value}"' for block in Block])
        blocks = f'[{blocks}]'
        return ('blocks: Identify any blocks that are referenced in the '
                f'question. The possible blocks are: {blocks}.')

    @staticmethod
    def json_for_prompt() -> str:
        return ' "blocks": string[]'
    
    @staticmethod
    def get_block_descriptions() -> str:
        return ('"body": The body of the page, e.g. the text in a '
                'Microsoft Word document.\n'
                '"comment": A comment on the page, e.g. a comment on a Jira '
                'ticket.\n'
                '"contact": A contact associated with an account in a CRM.\n'
                '"deal": A deal associated with an account in a CRM.\n'
                '"members": A list of members associated with the page, e.g. '
                'the author, recipients, etc.\n'
                '"summary": A summary of the page.\n'
                '"title": The title of the page.')

class SearchMethodValue(Enum):
    RELEVANT = 'relevant'
    EXACT = 'exact'

@dataclass
class SearchMethod(QueryComponent):
    '''Enforces the method by which results are returned.\n
    Examples:\n
    "all emails from Troy" => "exact"\n
    "emails from Troy related to the budget" => "relevant"'''
    value: SearchMethodValue

    @staticmethod
    def from_llm_response(llm_response: str) -> 'SearchMethod':
        try:
            value = SearchMethodValue(llm_response)
        except ValueError:
            print('Failed to create SearchMethod from LLM response:',
                  llm_response)
            return None
        return SearchMethod(value)
    
    @staticmethod
    def description_for_prompt() -> str:
        return ('search_method: Determine whether the question is looking '
                'for exact information or the most relevant information.')

    @staticmethod
    def json_for_prompt() -> str:
        return ' "search_method": "exact" OR "relevant"'

class ReturnTypeValue(Enum):
    PAGES = 'pages'
    BLOCKS = 'blocks'

@dataclass
class ReturnType(QueryComponent):
    value: str

    @staticmethod
    def from_llm_response(llm_response: str) -> 'ReturnType':
        try:
            value = ReturnTypeValue(llm_response)
        except ValueError:
            print('Failed to create ReturnType from LLM response:',
                  llm_response)
            return None
        return ReturnType(value)
    
    @staticmethod
    def description_for_prompt() -> str:
        return ('return_type: Determine whether the question is looking for '
                'entire pages or just blocks.')

    @staticmethod
    def json_for_prompt() -> str:
        return ' "return_type": "pages" OR "blocks"'

@dataclass
class Query:
    components: Dict[Type[QueryComponent], QueryComponent] = (
        field(default_factory=dict))
    question: str = None
    
    @staticmethod
    def from_llm_response(llm_response: Dict[str, Any]) -> 'Query':
        components = {}
        for key, value in llm_response.items():
            try:
                component_class = QueryComponent.get_component_from_json_key(
                    key)
            except ValueError:
                print(f'LLM produced invalid query component: {key}')
                continue
            component = component_class.from_llm_response(value)
            if component:
                components[component_class] = component
        return Query(components)
    
# ----------------------------------------------------------------------------
# Context
# ----------------------------------------------------------------------------

@dataclass
class Source:
    page_id: str
    integration: str

@dataclass
class Context:
    content: str 
    source: Source

@dataclass
class ContextBasket:
    contexts: List[Context] = field(default_factory=list) 

    def append(self, context: Context) -> None:
        self.contexts.append(context)

    def __iter__(self):
        return iter(self.contexts)

# ----------------------------------------------------------------------------
# Data Agent
# ----------------------------------------------------------------------------

class DataAgent(ABC):
    '''The data agent abstract class.'''
    _llm: OpenAIChat = None

    def __init__(
        self,
        owner: str,
        graph_db: Neo4j,
        vector_db: Pinecone,
        openai: OpenAI
    ) -> None:
        print('[DataAgent] Initializing...')
        self._owner: str = owner
        self._graph_db: Neo4j = graph_db
        self._vector_db: Pinecone = vector_db
        self._openai: OpenAI = openai
        if not self._llm:
            self._llm = OpenAIChat(client=openai, model='gpt-4')
        print('[DataAgent] Initialized.')
        print()

    def generate_context(
            self, question: str, query: Query = None) -> ContextBasket:
        if not query:
            print('[DataAgent] Generating prompt...')
            prompt = self._generate_prompt(question)
            print('[DataAgent] Prompt generated.')
            print(prompt.prompt)
            print()
            print('[DataAgent] Sending prompt to LLM to generate response...')
            llm_response = self._llm.predict(prompt)
            print('[DataAgent] LLM response received.')
            print(llm_response)
            print()
            print('[DataAgent] Parsing LLM response for query...')           
            query = _parse_llm_response_for_query(llm_response)
            print('[DataAgent] Query parsed.')
            print(query)
            print()
            query.question = question
        print('[DataAgent] Executing query...')
        if (SearchMethod in query.components and
            query.components[SearchMethod].value == SearchMethodValue.EXACT):
            context_basket = self._fetch_exact_context(query)
        elif (SearchMethod in query.components and
                query.components[SearchMethod].value ==
                SearchMethodValue.RELEVANT):
            if (NamesFilter in query.components
                and query.components[NamesFilter]):
                context_basket = self._fetch_relevant_context_with_names(query)
            else:
                context_basket = self._fetch_relevant_context_without_names(query)
        else:
            print('[DataAgent] Invalid SearchMethod. Defaulting to relevant.')
            context_basket = self._fetch_relevant_context_without_names(query)
        if len(context_basket.contexts) < 1:
            print('[DataAgent] No context found. Defaulting to relevant.')
            context_basket = self._fetch_relevant_context_without_names(query)
        print('[DataAgent] Query executed.')
        print(context_basket)
        print()
        for context in context_basket.contexts:
            print(context.content)
        return context_basket
        
    def _generate_prompt(
        self,
        question: str
    ) -> ChatPrompt:
        block_descriptions = BlocksFilter.get_block_descriptions()
        json_schema = QueryComponent.get_json_schema()
        component_descriptions = QueryComponent.get_component_descriptions()
        system_message = ChatPromptMessage(
            role=ChatPromptMessageRole.SYSTEM.value,
            content=SYSTEM_PROMPT.format(
                block_descriptions=block_descriptions,
                json_schema=json_schema,
                component_descriptions=component_descriptions
            )
        )
        user_message = ChatPromptMessage(
            role=ChatPromptMessageRole.USER.value,
            content=question
        )
        return ChatPrompt([system_message, user_message])
    
    def _fetch_relevant_context_without_names(
            self, query: Query) -> ContextBasket:
        results = self._query_neo4j(query)
        context_basket = ContextBasket()
        if results:
            for record in results:
                block_node = record.get('block', None) if record else None
                document_node = record.get('document', None) if record else None
                page_id = document_node.get('id', None) \
                    if document_node else None
                integration = document_node.get('integration', None) \
                    if document_node else None
                content = block_node.get('content', None) \
                    if block_node else None
                if not content:
                    continue
                context_basket.append(Context(
                    content=content,
                    source=Source(page_id=page_id, integration=integration)
                ))
        return context_basket
    
    def _fetch_relevant_context_with_names(
            self, query: Query) -> ContextBasket:
        results = self._query_neo4j(query)
        block_ids = []
        if results:
            for record in results:
                block_node = record.get('block', None) if record else None
                id_ = block_node.get('id', None) if block_node else None
                if id_:
                    block_ids.append(id_)
        block_embeddings = self._vector_db.fetch(block_ids)
        block_vectors = []
        if block_embeddings:
            block_vectors = [Vector(id=id_, embedding=vector.values)
                            for id_, vector in block_embeddings.items()]
        question_embedding = self._openai.embed(query.question)
        question_vector = Vector(id='', embedding=question_embedding)
        nearest_neighbors = _get_neighbors(question_vector, block_vectors)
        if not nearest_neighbors:
            return ContextBasket()
        block_filter = BlockFilter(
            ids=set([neighbor.id for neighbor in nearest_neighbors])
        )
        query_filter = QueryFilter(
            owner=self._owner,
            block_filter=block_filter
        )
        results = self._graph_db.get_by_filter(query_filter)
        context_basket = ContextBasket()
        if results:
            for record in results:
                block_node = record.get('block', None) if record else None
                document_node = record.get('document', None) if record else None
                page_id = document_node.get('id', None) \
                    if document_node else None
                integration = document_node.get('integration', None) \
                    if document_node else None
                content = block_node.get('content', None) \
                    if block_node else None
                if not content:
                    continue
                context_basket.append(Context(
                    content=content,
                    source=Source(page_id=page_id, integration=integration)
                ))
        return context_basket

    
    def _fetch_exact_context(self, query: Query) -> ContextBasket:
        results = self._query_neo4j(query)
        context_basket = ContextBasket()
        if results:
            for record in results:
                block_node = record.get('block', None) if record else None
                document_node = record.get('document', None) if record else None
                page_id = document_node.get('id', None) \
                    if document_node else None
                integration = document_node.get('integration', None) \
                    if document_node else None
                content = block_node.get('content', None) \
                    if block_node else None
                if not content:
                    continue
                context_basket.append(Context(
                    content=content,
                    source=Source(page_id=page_id, integration=integration)
                ))
        return context_basket
    
    def _query_neo4j(self, query: Query) -> Any:
        if not (query and query.components and query.question):
            return None
        
        integrations = None
        if IntegrationsFilter in query.components:
            integrations_filter: IntegrationsFilter = (
                query.components[IntegrationsFilter])
            integrations = set([_integration_name(integration)
                                for integration 
                                in integrations_filter.integrations])
            
        names = None
        if NamesFilter in query.components:
            names_filter: NamesFilter = query.components[NamesFilter]
            names = set(names_filter.names)

        min_date_day = None
        max_date_day = None
        if AbsoluteTimeFilter in query.components:
            absolute_time_filter: AbsoluteTimeFilter = (
                query.components[AbsoluteTimeFilter])
            min_date_day = absolute_time_filter.start
            max_date_day = absolute_time_filter.end
        time_range = None
        if min_date_day and max_date_day:
            time_range = (min_date_day, max_date_day)

        block_label = None
        if BlocksFilter in query.components:
            blocks_filter: BlocksFilter = query.components[BlocksFilter]
            block_label = [block.value for block in blocks_filter.blocks]

        order_by = None
        limit = None
        if RelativeTimeFilter in query.components:
            relative_time_filter: RelativeTimeFilter = (
                query.components[RelativeTimeFilter])
            order_by = OrderBy(
                direction=OrderDirection.ASC if relative_time_filter.ascending
                else OrderDirection.DESC,
                node='block',
                property='last_updated_timestamp'
            )
            limit = Limit(offset=0, count=relative_time_filter.count)

        query_filter = QueryFilter(
            owner=self._owner,
            document_filter=DocumentFilter(
                integrations=integrations,
                time_range=time_range,
            ),
            name_filter=NameFilter(
                names=names
            ),
            block_filter=BlockFilter(
                labels=block_label,
                time_range=time_range,
            ),
            order_by=order_by,
            limit=limit
        )

        results = self._graph_db.get_by_filter(query_filter)
        return results

    def _count_tokens(self, text: str) -> int:
        encoding = tiktoken.get_encoding(self._llm.encoding_name)
        tokens = encoding.encode(text)
        return len(tokens)
    
    def _context_basket_token_size(
            self, context_basket: ContextBasket) -> int:
        token_count = 0
        for context in context_basket:
            token_count += self._count_tokens(context.content)
        return token_count

def _parse_llm_response_for_query(llm_response: str) -> Query:
    match = re.search(r'{[\s\S]*}', llm_response, re.DOTALL)
    if match:
        stringified_json = match.group(0)
        query_json = json.loads(stringified_json)
        query = Query.from_llm_response(query_json)
        return query

def _format_date(date: str) -> int:
    return int(date.replace('-', ''))

def _integration_name(integration: Integration) -> str:
    if integration == Integration.CRM:
        return 'zoho'
    elif integration == Integration.CUSTOMER_SUPPORT:
        return 'zendesk'
    elif integration == Integration.DOCUMENTS:
        return 'google_docs'
    elif integration == Integration.EMAIL:
        return 'google_mail'

def _euclidean_distance(row1, row2):
    distance = 0.0
    for i in range(len(row1)-1):
        distance += (row1[i] - row2[i])**2
    return sqrt(distance)

@dataclass
class Vector:
    id: str
    embedding: List[float]
    distance = float = None

def _get_neighbors(query_vector: Vector, block_vectors: List[Vector],
                  num_neighbors: int = 5) -> List[Vector]:
    query_embedding = query_vector.embedding
    for block_vector in block_vectors:
        distance = _euclidean_distance(query_embedding, block_vector.embedding)
        block_vector.distance = distance
    sorted_block_vectors = sorted(block_vectors, key=lambda x: x.distance)
    return sorted_block_vectors[:num_neighbors]